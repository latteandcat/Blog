---
title: Spinning Up as a Deep RL Researcher（译） 
date: 2022-08-16
sidebar: auto
tags: 
 - DRL
categories:
 - DRL
---

::: tip
[原文地址](https://spinningup.openai.com/en/latest/spinningup/spinningup.html)
:::

如果你有志于成为一名 DRL 研究者，你可能已经听说了很多关于 DRL 的事情，你知道 DRL 很难并且有时效果很差。即使跟着教程一步一步来，DRL 的再现性也是一个挑战。如果你从头开始学习，学习曲线是非常陡峭的，虽然有很多可供学习的优秀资源，但并没有一个清晰明确的学习路径。本专栏的目标是帮助你跨越最初的障碍，让你清楚如何成为一个 DRL 研究者。特别的是，这将概述一个可以增加原始知识的课程，同时也能和一些零碎的知识结合以得到更好的研究。

## 背景知识

**建立扎实的数学基础。** 在概率和统计学里，你需要熟悉随机变量、贝叶斯定理、概率的链式法则、期望、标准差和重要性抽样。在多元微积分里，你需要理解梯度和泰勒展开公式。

**建立深度学习的常识框架。** 你不需要了解每一个特殊的技巧和架构，但是具备基础知识是很有用的。了解一些基础的结构（多层感知机、循环神经网络、LSTM、GRU、卷积层、resnets、注意力机制），了解一些常见的正则化方法（weight decay、dropout），了解一些常见的标准化方法（批标准化、层标准化、权重标准化）和一些常见的优化器（SGD、momentum SGD、Adam等等），以及了解重参数化的技巧。

**至少熟悉一个深度学习库。** 从 Tensorflow 或者 Pytorch 开始都可以，你不需要知道如何做所有的事情，但应该对实现一个简单的监督学习程序很有信心。

**熟悉RL中的主要概念和术语** 了解什么是状态、动作、轨迹、策略、奖励、价值函数、动作价值函数。如果你对这些概念还很陌生，SpinningUp 里有对这些材料的介绍。OpenAI Hackathon 的 RL-intro 和 Lilian Weng 的特别而全面的 RL 概述也值得一看。或者如果你是那种享受数学理论的人，你可以选择研究单调改进理论的数学方法或者经典的RL算法。

## 从实践中学习

**编写自己的算法实现。** 你应该从头开始实现尽可能多地实现核心的 DRL 算法，并以写出每个算法的最短正确实现为目的。到目前为止，这是了解它们如何工作的最好方法，也是了解它们具体性能特征的最好方法。

**简洁是至关重要的。** 你应该循序渐进的将算法用于自己的工作，最开始只需要实现最简单的算法，然后逐渐增加复杂性。如果你开始就去构建一个有太多组件的项目，那么它可能一开始就会出现问题，并且需要耗费几周的时间来调试。对于刚接触 DRL 的人来说，这是一种常见的失败模式，如果你发现自己陷入了这种模式，不要灰心丧气，但在以后遇到更复杂的任务是一定要尝试改变方向使用更简单的算法。

**如何选择算法？** 你可能会从 VPG、DQN、A2C、PPO 和 DDPG 开始学习，大致按照这个顺序。这些算法的最简版本都可以用几百行代码实现甚至更少。在尝试编写这些算法的并行版本之前先编写单线程代码，至少对一个算法尝试并行化。

**专注于理解。** 编写有效的 RL 代码需要对算法有清晰的、面向细节的理解。这也是破碎的 RL 代码经常无声无息地失败地原因，有时候虽然代码看起来运行良好，但是智能体并未学习到完成任务的能力。

## 开发一个研究项目

## 严谨地研究RL

## 结语

## 其他资源